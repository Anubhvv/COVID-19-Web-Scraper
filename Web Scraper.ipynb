{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    \"\"\"\n",
    "    Clean the script tag contents for easier retrieval of data.\n",
    "    \n",
    "    paramters:\n",
    "        string: str.\n",
    "        The contents of the script tag.\n",
    "        \n",
    "    returns:\n",
    "        string: str.\n",
    "        The cleaned contents of the script tag.\n",
    "    \"\"\"\n",
    "    \n",
    "    string = re.sub(\"[\\n \\\\\\']\",'',str(string))\n",
    "    string = string.replace(\" \",'')\n",
    "    string = re.sub('[{}\\[\\]():]',' ',string)\n",
    "    string = re.sub('[\\\"\\\" /*]','',string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_dates(string):\n",
    "    \"\"\"\n",
    "    Retrieve dates from the cleaned script tag contents.\n",
    "    \n",
    "    parameters:\n",
    "        string: str.\n",
    "        The cleaned contents of the script tag.\n",
    "        \n",
    "    returns:\n",
    "        dates: list.\n",
    "        A list of the dates.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_string = 'categories'\n",
    "    end_string = ',yAxis'\n",
    "    \n",
    "    start_index = string.find(start_string) + len(start_string)\n",
    "    end_index = string.find(end_string)\n",
    "    \n",
    "    dates = string[start_index:end_index].strip().split(\",\")\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_daily_stats(string):\n",
    "    \"\"\"\n",
    "    Retrieves daily statistics from the cleaned script tag contents.\n",
    "    \n",
    "    parameters:\n",
    "        string: str.\n",
    "        Cleaned contents of the script tag.\n",
    "                \n",
    "    returns:\n",
    "        values: list.\n",
    "        A list of daily statistics ordered by date.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_string = 'data'\n",
    "    end_string = ',name'\n",
    "    \n",
    "    start_index = string.find(start_string) + len(start_string)\n",
    "    end_index = string.find(end_string)\n",
    "    \n",
    "    values = string[start_index:end_index].strip().split(\",\")\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_overall_stats(string):\n",
    "    \"\"\"\n",
    "    Retrieves overall statistics from the cleaned script tag contents.\n",
    "    \n",
    "    parameters:\n",
    "        string: str.\n",
    "        Cleaned contents of the script tag.\n",
    "        \n",
    "    returns:\n",
    "        values: list.\n",
    "        A list of daily statistics ordered by date.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_string = 'data'\n",
    "    end_string = ',resp'\n",
    "    \n",
    "    start_index = string.find(start_string) + len(start_string)\n",
    "    end_index = string.find(end_string)\n",
    "    \n",
    "    values = string[start_index:end_index].strip().split(\",\")\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "url = \"https://www.worldometers.info/coronavirus/country/\"+country+\"/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "result = soup.find_all('div',class_='col-md-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'us','brazil','russia','spain',\n",
    "    'italy','france','germany',\n",
    "    'turkey','india','iran','peru',\n",
    "    'canada','chile','china','mexico',\n",
    "    'saudi-arabia','pakistan','belgium',\n",
    "    'qatar', 'bangladesh',\n",
    "    'belarus', 'ecuador', 'sweden'\n",
    "]\n",
    "\n",
    "\n",
    "data_indexes = {\n",
    "                'total_cases':0,\n",
    "                'daily_cases':1,\n",
    "                'active_cases':2,\n",
    "                'total_deaths':3,\n",
    "                'daily_deaths':4\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_contents(url):\n",
    "    \"\"\"\n",
    "    Retrieves contents of the web page from the specified url and the specific div tag class - col-md-12\n",
    "    \n",
    "    paramters:\n",
    "        url: str.\n",
    "        The url to the web page to be scrapped.\n",
    "        \n",
    "    returns:\n",
    "        result: str.\n",
    "        HTML parsed web page content as string.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    result = soup.find_all('div', class_= 'col-md-12')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_tag_contents(page_content, stat):\n",
    "    \"\"\"\n",
    "    Retrieves the script tag contents from the web page contents.\n",
    "    \n",
    "    paramters:\n",
    "        page_content: str.\n",
    "        HTML parsed web page contents\n",
    "        \n",
    "        stat: str.\n",
    "        String specifying the kind of statistic from the data_indexes.\n",
    "        \n",
    "    returns:\n",
    "        script_content: str.\n",
    "        Script tag contents as string.\n",
    "    \"\"\"\n",
    "    \n",
    "    stat_data = page_content[data_indexes[stat]]\n",
    "    script_content = stat_data.find('script').contents[0]\n",
    "    \n",
    "    return script_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(values,stat_name,dataframe=None,date=None):\n",
    "    \"\"\"\n",
    "    Build a DataFrame from the dates and the values scraped.\n",
    "    \n",
    "    parameters:\n",
    "        dataframe: DataFrame.\n",
    "        A DataFrame containing dates and/or statistics.\n",
    "        \n",
    "        date: list.\n",
    "        List of dates for the statistics in string format.\n",
    "        \n",
    "        values: list:\n",
    "        List of values (data) for the statistics in string format.\n",
    "        \n",
    "        stat_name: str.\n",
    "        Name of the statistic, for which the list of values are passed.\n",
    "        \n",
    "        returns:\n",
    "            dataframe: DataFrame.\n",
    "            DataFrame containing dates and passed statistic values.\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataframe is None and date is not None:\n",
    "        \n",
    "        dataframe = pd.DataFrame({'date':date, stat_name:values})\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dataframe[stat_name] = values\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(dataframe, date_col):\n",
    "    \"\"\"\n",
    "    Clean the date column in the dataframe to standard date representation - YYYY-MM-DD\n",
    "    \n",
    "    parameters:\n",
    "        dataframe: DataFrame.\n",
    "            DataFrame whose dates are to be cleaned.\n",
    "            \n",
    "        date_col: str.\n",
    "        Name of the date column in the DataFrame.\n",
    "        \n",
    "    returns:\n",
    "        dataframe: DataFrame.\n",
    "        Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe[date_col] = dataframe[date_col].apply(\n",
    "        lambda date: date[:3]+\" \"+date[3:]+\" 2020\"\n",
    "    )\n",
    "    dataframe[date_col] = dataframe[date_col].apply(\n",
    "        lambda date: datetime.datetime.strptime(date,'%b %d %Y').date()\n",
    "    )\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data():\n",
    "    \"\"\"\n",
    "    Scrape the web page for date, total cases, daily cases, total active cases, total_deaths, daily deaths\n",
    "    daily recoveries per country. Creates a folder in local directory containing csv files per country with \n",
    "    the respective data. Website - worldometers.info\n",
    "    \n",
    "    parameters: None\n",
    "    \n",
    "    returns: bool.\n",
    "    boolean.\n",
    "    \"\"\"\n",
    "    \n",
    "    has_been_run_once = False\n",
    "        \n",
    "    for country in countries:\n",
    "                \n",
    "        url = \"https://www.worldometers.info/coronavirus/country/\"+country+\"/\"\n",
    "        content = page_contents(url)\n",
    "        \n",
    "        for stat in data_indexes:\n",
    "                        \n",
    "            script_contents = script_tag_contents(content, stat)\n",
    "            script_contents = clean(script_contents)\n",
    "            \n",
    "            if 'daily' in stat:\n",
    "                \n",
    "                data = retrieve_daily_stats(script_contents)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data = retrieve_overall_stats(script_contents)\n",
    "                \n",
    "            if not has_been_run_once:\n",
    "                \n",
    "                date = retrieve_dates(script_contents)\n",
    "                dataframe = build_dataframe(data, stat, date= date)\n",
    "                has_been_run_once = True\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                dataframe = build_dataframe(data, stat, dataframe= dataframe)\n",
    "            \n",
    "        dataframe = clean_date(dataframe, date_col='date')\n",
    "        dataframe.to_csv('./Data/covid19_'+country+'_stats.csv',index=False)\n",
    "        has_been_run_once = False\n",
    "        print(\"Scraped successfully: \",country)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped successfully:  us\n",
      "Scraped successfully:  brazil\n",
      "Scraped successfully:  russia\n",
      "Scraped successfully:  spain\n",
      "Scraped successfully:  italy\n",
      "Scraped successfully:  france\n",
      "Scraped successfully:  germany\n",
      "Scraped successfully:  turkey\n",
      "Scraped successfully:  india\n",
      "Scraped successfully:  iran\n",
      "Scraped successfully:  peru\n",
      "Scraped successfully:  canada\n",
      "Scraped successfully:  chile\n",
      "Scraped successfully:  china\n",
      "Scraped successfully:  mexico\n",
      "Scraped successfully:  saudi-arabia\n",
      "Scraped successfully:  pakistan\n",
      "Scraped successfully:  belgium\n",
      "Scraped successfully:  qatar\n",
      "Scraped successfully:  bangladesh\n",
      "Scraped successfully:  belarus\n",
      "Scraped successfully:  ecuador\n",
      "Scraped successfully:  sweden\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>daily_cases</th>\n",
       "      <th>active_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>daily_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>144950</td>\n",
       "      <td>6414.0</td>\n",
       "      <td>80072</td>\n",
       "      <td>4172</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>150793</td>\n",
       "      <td>5843.0</td>\n",
       "      <td>82172</td>\n",
       "      <td>4344</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>158086</td>\n",
       "      <td>7293.0</td>\n",
       "      <td>85803</td>\n",
       "      <td>4534</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>165386</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>89755</td>\n",
       "      <td>4711</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>173491</td>\n",
       "      <td>8105.0</td>\n",
       "      <td>85884</td>\n",
       "      <td>4980</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  total_cases  daily_cases  active_cases  total_deaths  \\\n",
       "0    2020-02-15            3          NaN             0             0   \n",
       "1    2020-02-16            3          0.0             0             0   \n",
       "2    2020-02-17            3          0.0             0             0   \n",
       "3    2020-02-18            3          0.0             0             0   \n",
       "4    2020-02-19            3          0.0             0             0   \n",
       "..          ...          ...          ...           ...           ...   \n",
       "100  2020-05-25       144950       6414.0         80072          4172   \n",
       "101  2020-05-26       150793       5843.0         82172          4344   \n",
       "102  2020-05-27       158086       7293.0         85803          4534   \n",
       "103  2020-05-28       165386       7300.0         89755          4711   \n",
       "104  2020-05-29       173491       8105.0         85884          4980   \n",
       "\n",
       "     daily_deaths  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "..            ...  \n",
       "100         148.0  \n",
       "101         172.0  \n",
       "102         190.0  \n",
       "103         177.0  \n",
       "104         269.0  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/covid19_india_stats.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_contents(url):\n",
    "    \"\"\"\n",
    "    Retrieve contents of the table on the url.\n",
    "    \n",
    "    parameters:\n",
    "        url: str.\n",
    "        URL of the webpage. The table contents are scraped from this.\n",
    "        \n",
    "    returns:\n",
    "        table_data: str.\n",
    "        HTML parsed table data in string format.\n",
    "    \"\"\"\n",
    "    \n",
    "    page_content = requests.get(url)\n",
    "    soup = BeautifulSoup(page_content.content, 'html.parser')\n",
    "    table_data = soup.find('table', id='thetable')\n",
    "    \n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_names(table_data):\n",
    "    \"\"\"\n",
    "    Scrape country names from the table contents scraped from the Wikipedia url.\n",
    "    \n",
    "    parameters:\n",
    "        table_data: str.\n",
    "        Scraped table data from webpage in string format.\n",
    "        \n",
    "    returns:\n",
    "        countries: list.\n",
    "        A list of country names from the table on webpage.\n",
    "    \"\"\"\n",
    "    \n",
    "    countries= []\n",
    "    table_head_data = table_data.find_all('th', scope= 'row')\n",
    "    \n",
    "    for data in table_head_data:\n",
    "        \n",
    "        anchor_data = data.find('a')\n",
    "        \n",
    "        if anchor_data is not None:\n",
    "            \n",
    "            countries.append(anchor_data.contents[0])\n",
    "    \n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, size):\n",
    "    \"\"\"\n",
    "    Segments the input list into equal chunks of specified size.\n",
    "    \n",
    "    parameters:\n",
    "        lst: list.\n",
    "        List to be segmented.\n",
    "        \n",
    "        size: int.\n",
    "        Size of the chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(0, len(lst), size):\n",
    "        \n",
    "        yield lst[i:i+size]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(stats):\n",
    "    \"\"\"\n",
    "    Clean the statistics scraped from the webpage. Remove ',' and '\\n'.\n",
    "    \n",
    "    parameters:\n",
    "        stats: list.\n",
    "        A list of statistics.\n",
    "        \n",
    "    returns:\n",
    "        cleaned_stats: list.\n",
    "        A cleaned list of statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_stats = []\n",
    "    \n",
    "    for stat in stats:\n",
    "        \n",
    "        stat = re.sub(',','',stat)\n",
    "        stat = stat.rstrip()\n",
    "        cleaned_stats.append(stat)\n",
    "        \n",
    "    cleaned_stats.pop()\n",
    "    \n",
    "    return cleaned_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_statistics(table_data):\n",
    "    \"\"\"\n",
    "    Scrape overall statistics on total cases, total deaths and total recoveries from \n",
    "    the table contents on the webpage, for each country.\n",
    "    \n",
    "    parameters:\n",
    "        table_data: str.\n",
    "        Scraped table data in string format.\n",
    "        \n",
    "    returns:\n",
    "        stats: list.\n",
    "        A list of lists giving country wise statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    row_data = table_data.find_all('td')\n",
    "    \n",
    "    for data in row_data:\n",
    "        \n",
    "        if data.find('sup'):\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if data.find('span'):\n",
    "            \n",
    "            stats.append('null')\n",
    "            continue\n",
    "        \n",
    "        stats.append(data.contents[0])\n",
    "        \n",
    "    stats = clean_stats(stats)    \n",
    "    stats = list(chunks(stats,3))\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_overall_data():\n",
    "    \"\"\"\n",
    "    Scrape overall statistics country wise from the Wikipedia page on COVID-19 pandemic into a DataFrame.\n",
    "    Writes the DataFrame to a csv file.\n",
    "    \n",
    "    returns: bool.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://en.wikipedia.org/wiki/COVID-19_pandemic_by_country_and_territory'\n",
    "    table_data = table_contents(url)\n",
    "    \n",
    "    countries = country_names(table_data)\n",
    "    statistics = table_statistics(table_data)\n",
    "    \n",
    "    statistics_dict = {}\n",
    "    \n",
    "    for country, statistic in zip(countries, statistics):\n",
    "        \n",
    "        statistics_dict[country] = statistic\n",
    "        \n",
    "    dataframe = pd.DataFrame.from_dict(statistics_dict, orient= 'index', columns= [\n",
    "        'total_cases',\n",
    "        'total_deaths',\n",
    "        'total_recoveries'\n",
    "    ]).reset_index()\n",
    "    \n",
    "    dataframe.rename(columns= {'index':'country'}, inplace= True)\n",
    "    dataframe.to_csv('./Data/covid19_overall_stat.csv', index= False)\n",
    "    \n",
    "    print(\"Successfully scraped table\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_overall_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recoveries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1783132</td>\n",
       "      <td>104166</td>\n",
       "      <td>384821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>468338</td>\n",
       "      <td>27944</td>\n",
       "      <td>189476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russia</td>\n",
       "      <td>387623</td>\n",
       "      <td>4374</td>\n",
       "      <td>159257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>271222</td>\n",
       "      <td>38161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>238564</td>\n",
       "      <td>27121</td>\n",
       "      <td>150376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Saba</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Bonaire</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Lesotho</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Sint Eustatius</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Saint Pierre &amp; Miquelon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     country  total_cases  total_deaths  total_recoveries\n",
       "0              United States      1783132        104166          384821.0\n",
       "1                     Brazil       468338         27944          189476.0\n",
       "2                     Russia       387623          4374          159257.0\n",
       "3             United Kingdom       271222         38161               NaN\n",
       "4                      Spain       238564         27121          150376.0\n",
       "..                       ...          ...           ...               ...\n",
       "223                     Saba            3             0               3.0\n",
       "224                  Bonaire            2             0               2.0\n",
       "225                  Lesotho            2             0               1.0\n",
       "226           Sint Eustatius            2             0               2.0\n",
       "227  Saint Pierre & Miquelon            1             0               1.0\n",
       "\n",
       "[228 rows x 4 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./Data/covid19_overall_stat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_stats(url):\n",
    "    \"\"\"\n",
    "    Gathers updated data on the number of cases and deaths in a day.\n",
    "    \n",
    "    paramters:\n",
    "        url: str.\n",
    "        URL from where the updates are scraped.\n",
    "        \n",
    "    returns:\n",
    "        result: tuple.\n",
    "        A tuple with total cases and total deaths of the day.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    updated_list = soup.find('li', class_= 'news_li')\n",
    "    updates = updated_list.find_all('strong')\n",
    "    \n",
    "    daily_cases = updates[0].contents[0]\n",
    "    daily_deaths = updates[1].contents[0]\n",
    "    \n",
    "    daily_cases = re.sub('[, new cases]','',daily_cases)\n",
    "    daily_deaths = re.sub('[, new deaths]','',daily_deaths)\n",
    "    \n",
    "    result = (int(daily_cases), int(daily_deaths))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25,069 new cases']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.worldometers.info/coronavirus/country/us/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "updates = soup.find('li',class_='news_li').find_all('strong')\n",
    "updates[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25069, 1212)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_stats(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
